{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a35ce3e",
   "metadata": {},
   "source": [
    "# ✅ pandas cheat sheet ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915fec7",
   "metadata": {},
   "source": [
    "## Creating and inspecting DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd347481",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "At the heart of pandas lies the DataFrame, a powerful data structure organizing data into neat rows and columns, mirroring how we conceptualize information. Think of it like a spreadsheet where each row represents a unique entry where these entries could be a person or a transaction, and each column represents a specific characteristic of those entries like age, name, or purchase amount. pandas offers diverse ways to create DataFrames, accommodating various data sources. These sources can come from dictionaries, lists of lists, and CSV files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c7fc0",
   "metadata": {},
   "source": [
    "### dictionaries \n",
    "are ideal for structured data, where each key represents a column's name and each value corresponds to a column's data.This is particularly useful when you have data stored in a dictionary format, perhaps after processing JSON data or extracting information from a database.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e3785",
   "metadata": {},
   "source": [
    "so the onlything you need to do is using .Dataframe() method to convert  a dictionary into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 28]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9b8f3",
   "metadata": {},
   "source": [
    "### LIST OF LISTS\n",
    "LIST Aof lists are great for tablular data. Each inner list represents a row, and an optional columns argument specifies column names.This method is handy when you have data organized in a list-of-lists format, perhaps after reading data from a text file or scraping a website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ca7cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age\n",
      "0    Alice   25\n",
      "1      Bob   30\n",
      "2  Charlie   28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = [['Alice', 25], ['Bob', 30], ['Charlie', 28]]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32d0bd3",
   "metadata": {},
   "source": [
    "### CSV \n",
    "files give pandas the ability to seamlessly load data from them into DataFrames using the read_csv function. This function handles parsing and structuring. CSV files are a common format for storing and exchanging data, and pandas makes it effortless to import them into your Python environment for analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc649f60",
   "metadata": {},
   "source": [
    "pandas also provides similar functions like\n",
    "🧐 read_excel, \n",
    "🧐read_json, \n",
    "🧐 read_sql \n",
    "for importing data from other popular formats, making it adaptable to your specific data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b648d2b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0414f739",
   "metadata": {},
   "source": [
    "# Inspecting a Dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47148e26",
   "metadata": {},
   "source": [
    "Once you have your DataFrame ready, pandas provides a suite of functions to explore and understand its structure and content:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e85dfde",
   "metadata": {},
   "source": [
    "🧐df.head(): Displays the first few rows (default 5) for a quick overview of the data's nature, including column names, data types, and a sample of values. It's like taking a peek at the beginning of a dataset to get a feel for what it contains.\n",
    "\n",
    "🧐df.tail(): Similarly, displays the last few rows (default 5), aiding in identifying patterns or anomalies towards the end. This can be helpful in spotting any unexpected values or trends that might require further investigation.\n",
    "\n",
    "🧐df.shape: Returns a tuple representing the dimensions of the DataFrame (number of rows and columns). This is crucial for understanding the scale of your data and planning your analysis strategy accordingly.\n",
    "\n",
    "🧐df.info(): Generates a concise summary of the DataFrame, encompassing column names, data types (essential for knowing how to work with each column), and the presence of missing values. This summary provides a quick health check of your data, highlighting potential areas for cleaning or preprocessing.\n",
    "\n",
    "🧐df.describe(): Computes descriptive statistics for numerical columns, offering insights into data distribution and central tendencies. This includes metrics like count, mean, standard deviation, minimum, maximum, and quartiles, which help you understand the characteristics of your numerical data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc6072b",
   "metadata": {},
   "source": [
    "## Selecting and filtering data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25611425",
   "metadata": {},
   "source": [
    "The true power of pandas lies in its ability to precisely select and filter data, allowing you to focus your analysis on specific subsets of interest. This capability is fundamental for extracting meaningful information from large and complex datasets. pandas provides intuitive syntax for column selection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0adf1",
   "metadata": {},
   "source": [
    "🧐Single column selection \n",
    "retrieves a single column by its name using square brackets. The result is a pandas Series, a one-dimensional labeled array capable of holding any data type. Series objects inherit many of the DataFrame's functionalities, enabling further manipulation and analysis on a single column.\n",
    "\n",
    "df['Age'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a421e",
   "metadata": {},
   "source": [
    "Multiple column selection extracts multiple columns by passing a list of column names within double square brackets. The output is a new DataFrame containing only the selected columns, effectively creating a focused subset of the original data. This is useful when you want to work with a specific group of variables or features.\n",
    "\n",
    "df[['Name', 'Age']] \n",
    "\n",
    "pandas offers two primary methods for row selection, each tailored to specific indexing needs.\n",
    "\n",
    "df.loc[] employs label-based indexing, allowing you to select rows based on their index labels, which can be strings, integers, or even dates. This is particularly helpful when your DataFrame has meaningful index labels that you want to use for selection.\n",
    "\n",
    "df.loc[0]       # Select the row with index label 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd1788",
   "metadata": {},
   "source": [
    "df.iloc[] leverages integer-based indexing, enabling row selection based on their integer positions (starting from 0). This is useful when you want to select rows based on their order in the DataFrame, regardless of their index labels.\n",
    "\n",
    "df.iloc[0]      # Select the first row (position 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7136162",
   "metadata": {},
   "source": [
    "Filtering data is done with Boolean indexing and serves as a powerful tool for filtering rows based on specific conditions. It involves creating a boolean mask (a Series of True/False values) by applying comparison operators or logical conditions to one or more columns. This mask is then used to select only the rows where the condition evaluates to True, effectively filtering the DataFrame based on your criteria. This allows you to extract subsets of data that meet specific requirements, facilitating targeted analysis.\n",
    "\n",
    "df[df['Age'] > 25]  # Filter rows where 'Age' is greater than 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb8dbd4",
   "metadata": {},
   "source": [
    "Querying data is for more complex filtering scenarios involving multiple conditions or intricate logic. The query method offers a SQL-like syntax. This enhances readability and expressiveness, allowing you to construct queries that resemble natural language expressions, making your code more intuitive and maintainable. It's particularly beneficial when dealing with intricate filtering criteria that would be cumbersome to express using traditional boolean indexing.\n",
    "\n",
    "df.query('Age > 25 and Name == \"Bob\"') # Filter rows based on multiple conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f4853",
   "metadata": {},
   "source": [
    "# missing values :\n",
    "Real-world datasets are rarely perfect; missing values, denoted as NaN, are common to find. These missing values can come from various sources, such as data entry errors, sensor malfunctions, or incomplete surveys. pandas provides robust mechanisms for identifying and addressing these missing values, ensuring the integrity of your analysis and preventing potential errors or biases that can skew your results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2d4920",
   "metadata": {},
   "source": [
    "### df.isnull() \n",
    "generates a boolean DataFrame mirroring the original, where True indicates a missing value and False represents a non-missing value. This provides a comprehensive overview of the missing data landscape within your DataFrame, allowing you to quickly assess the extent of what is missing and identify columns or rows that require attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34002915",
   "metadata": {},
   "source": [
    "## df['Age'].isnull()\n",
    " applies the same logic to a specific column, returning a boolean series highlighting missing values within that column. This allows you to focus your attention on specific variables and assess for their completeness, which is important for deciding on appropriate imputation strategies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66fc48e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name    Age\n",
      "0  False  False\n",
      "1  False   True\n",
      "2   True  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Ali', 'Sara', None],\n",
    "    'Age': [23, None, 30]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce57201",
   "metadata": {},
   "source": [
    "# Strategies for handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa33647",
   "metadata": {},
   "source": [
    "### 1- df.dropna() \n",
    "removes rows containing any missing values, effectively shrinking the DataFrame but ensuring data completeness. This approach is suitable when missing values are relatively sparse and their removal doesn't significantly impact the representativeness of the data. However, it's important to exercise caution, as dropping rows can lead to loss of valuable information if not done judiciously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32f5b46",
   "metadata": {},
   "source": [
    "## 2- fillna()\n",
    "eplaces missing values with a specified value (e.g., 0), a simple imputation technique suitable for certain cases. This can be useful when you have a reasonable assumption about the likely value of missing data or when you want to avoid discarding rows altogether. However, it's important to consider the potential implications of this imputation on your analysis, as it might introduce bias or distort the underlying patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c50508",
   "metadata": {},
   "source": [
    "# 3- df['Age'].fillna(df['Age'].mean(), inplace=True) \n",
    "is a more sophisticated approach, imputing missing values in a column with its mean. The inplace=True argument modifies the DataFrame directly, conserving memory. This method is often preferred when missing values are assumed to be randomly distributed and you want to maintain the overall statistical properties of the data\n",
    "\n",
    "It's important to be aware that mean imputation can underestimate variance and potentially mask underlying patterns in the data. Other imputation techniques, such as median imputation or more advanced methods like regression imputation or multiple imputation, might be more appropriate depending on the specific characteristics of your dataset and the nature of what is missing.\n",
    "\n",
    "pandas is an important tool for anyone navigating the world of data. It offers a comprehensive suite of functions and syntax to streamline data manipulation tasks. By learning these functions, you'll be well-equipped to confront diverse data challenges and unveil valuable insights while you work. Remember, practice is key to solidifying your understanding and proficiency with these tools. Explore real-world datasets and spend time experimenting with all the possibilities that pandas offers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570558d",
   "metadata": {},
   "source": [
    "# DATA FRAME MANIPULATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef1e4c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age       City\n",
      "0    Alice   25  Vancouver\n",
      "1      Bob   30    Toronto\n",
      "2  Charlie   22   Montreal\n"
     ]
    }
   ],
   "source": [
    "# use .set_index(\"column name\")\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 22],\n",
    "    'City': ['Vancouver', 'Toronto', 'Montreal']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set \"Name\" column as the index\n",
    "df = df.set_index('Name')\n",
    "df = df.reset_index()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2af40d",
   "metadata": {},
   "source": [
    "if you have already index names u can use :df.rename(index={'Alice': 'Alicia', 'Bob': 'Bobby'}, inplace=True)\n",
    "if ur index are set as initial indexes(0,1,2,3,)\n",
    "u can use df.index = ['student_1', 'student_2', 'student_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2a32b",
   "metadata": {},
   "source": [
    "✅ 2. Rename the Index Title (the name of the index column)\n",
    "\n",
    "If you want to give a name to the index itself (not its values), do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = \"index name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d812f82f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "What you want to change\n",
    "Code\n",
    "Rename a column header - df.rename(columns={'Old': 'New'})\n",
    "Rename the index label - df.rename(index={'OldLabel': 'NewLabel'})\n",
    "Rename the index title (not values) - df.index.name = 'NewTitle\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
